# 研发方向思考

## clickhouse的核心特性

- 完备的DBMS功能：DDL，DML，权限控制，数据备份与恢复，分布式管理
- 列式存储与数据压缩
- 向量化执行引擎：向量化模型 + processor并行调度。

> 查询执行引擎分三种：火山模型（又叫pipeline模型，是pull-based）、向量化模型、代码生成（是push-based）。

> 向量化执行依赖于CPU的SIMD指令。

- 关系模型与SQL查询
- 多样化的表引擎
- 多线程与分布式

> 向量化执行属于数据级并行，多线程处理属于线程级并行。SIMD指令不适合用于带有较多分支判断的场景，多线程技术因此和向量化执行形成互补。

> 分布式表现在数据层面的，既支持分区（纵向扩展，利用多线程原理），也支持分片（横向扩展，利用分布式原理）。

- 多主架构：天然规避单点故障问题，适用于多数据中心、异地多活场景。
- 在线查询：低延迟响应。
- 数据分片与分布式查询

> clickhouse的数据分片的问题是不够自动化，配置复杂，也没有数据的自动rebalance功能。

## clickhouse的缺点

- 缺少一个完善的优化器，只有5条简单的RBO规则，没有CBO。
- 多表查询性能差：join方式单一，只支持broadcast join，并且只能右表广播。
- 没有shuffle：导致final aggregate无法并行计算，只能汇总到一个节点。
- 不支持分布式查询计划：分布式表只是一种妥协方案。
- 缺少统一的元数据服务，导到维护各节点元数据的一致性成本较高。
- 数据的分片和副本的方式不灵活：shard和replica需要用户控制，运维极其复杂。
- 缺少完善的多租户管理、资源隔离功能。
- 不支持事务。
- 异步的数据删除和更新（不够实时）。
- 不适用高并发场景。
- 代码上的问题：各模块耦合程度太高，如计算和存储逻辑的耦合、逻辑计划和物理计划的耦合。

## vectbase产品的价值

- 仿snowflake的价值：存算分离、弹性伸缩、厂商中立

- 多模数据库：全文检索、宽表模型、图数据库

- 联邦查询：查询多种数据源，包括hive、hbase、es等

- 元数据理解：[元数据就是大数据](https://www.vldb.org/pvldb/vol14/p3083-edara.pdf)、数据安全、隐私加密

- 混合负载：即席查询和批处理查询

- 湖仓一体

- 混合云：公有云+私有云

## 优化方向

| 特性                        | 收益                   | 方案                                                         | 参考                   |
| --------------------------- | ---------------------- | ------------------------------------------------------------ | ---------------------- |
| 数据按partition key分布     |                        | 由master/coordinator节点作partiton placement                 |                        |
| storage-aware               |                        |                                                              | AnalyticDB             |
| shuffle join                |                        |                                                              | GreenPlum              |
| 读写分离                    |                        |                                                              | AnalyticDB             |
| MPP+DAG                     |                        |                                                              |                        |
| 计算下推                    | 优化存算分离的查询性能 |                                                              | TiDB，《极客时间》课程 |
| join下推（colocation join） | 优化存算分离的查询性能 | 数据按sharding key分布，两表join的数据位于同一节点。或叫local join。消灭shuffle。 |                        |
| 分片索引或全局索引          | 优化存算分离的查询性能 |                                                              |                        |
| 向量化                      | 全面向量化             |                                                              |                        |
| CBO vs codegen              |                        |                                                              |                        |
| 透明的物化视图              | 只需查底表             |                                                              |                        |
| 实时update、delete          | 实时数据分析能力       | merge-on-read vs delete-and-insert                           | starrocks              |
| 联邦查询对接数据湖存储      |                        |                                                              |                        |
| 查hive数据，计算侧在ck      |                        |                                                              | starrocks              |
| 全局字典                    | 查询优化               |                                                              |                        |